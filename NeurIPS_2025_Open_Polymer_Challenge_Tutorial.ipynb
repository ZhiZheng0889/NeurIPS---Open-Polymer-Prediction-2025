{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_molecule\n",
        "\n"
      ],
      "metadata": {
        "id": "PmC63oIvaX7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hu3Oete5BYvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdIOIlsFA6Aw"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "csv_path = 'train.csv'\n",
        "train_df = pd.read_csv(csv_path)\n",
        "\n",
        "# 1. split off 20% for dev_test\n",
        "temp_df, dev_test = train_test_split(\n",
        "    train_df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,  # for reproducibility\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# 2. split the remaining 80% into 75% train / 25% valid â†’ 0.6 / 0.2 overall\n",
        "dev_train, dev_val = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.25,  # 0.25 * 0.8 = 0.2 of the original\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Verify sizes\n",
        "print(f\"Total rows:   {len(train_df)}\")\n",
        "print(f\"Dev train:    {len(dev_train)} ({len(dev_train)/len(train_df):.2%})\")\n",
        "print(f\"Dev valid:    {len(dev_val)} ({len(dev_val)/len(train_df):.2%})\")\n",
        "print(f\"Dev test:     {len(dev_test)} ({len(dev_test)/len(train_df):.2%})\")\n",
        "print(f\"Polymer example:{dev_train['SMILES'].to_list()[:3]}\")\n",
        "print(f\"Columns:{dev_train.columns}\")"
      ],
      "metadata": {
        "id": "ppA_ZmnGA_UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm as notebook_tqdm\n",
        "import tqdm\n",
        "tqdm.tqdm = notebook_tqdm\n",
        "tqdm.trange = notebook_tqdm\n",
        "\n",
        "from torch_molecule import LSTMMolecularPredictor\n",
        "from torch_molecule.utils.search import ParameterType, ParameterSpec\n",
        "\n",
        "search_parameters = {\n",
        "    \"output_dim\": ParameterSpec(ParameterType.INTEGER, (8, 32)),\n",
        "    \"LSTMunits\": ParameterSpec(ParameterType.INTEGER, (30, 120)),\n",
        "    \"learning_rate\": ParameterSpec(ParameterType.LOG_FLOAT, (1e-4, 1e-2)),\n",
        "}\n",
        "\n",
        "lstm = LSTMMolecularPredictor(\n",
        "    task_type=\"regression\",\n",
        "    num_task=5,\n",
        "    batch_size=192,\n",
        "    epochs=200,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Model initialized successfully\")\n",
        "X_train = dev_train['SMILES'].to_list()\n",
        "y_train = dev_train[['Tg', 'FFV', 'Tc', 'Density', 'Rg']].to_numpy()\n",
        "X_val = dev_val['SMILES'].to_list()\n",
        "y_val = dev_val[['Tg', 'FFV', 'Tc', 'Density', 'Rg']].to_numpy()\n",
        "lstm.autofit(\n",
        "    X_train = X_train,\n",
        "    y_train = y_train,\n",
        "    X_val = X_val,\n",
        "    y_val = y_val,\n",
        "    search_parameters=search_parameters,\n",
        "    n_trials = 10 # number of times searching the best hyper-parameters\n",
        ")"
      ],
      "metadata": {
        "id": "1mOdKd32B9cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S4YFY7BwCfH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def smiles_to_fp(smiles, radius=2, nBits=1024):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits))\n",
        "\n",
        "# Convert SMILES to fingerprint features\n",
        "X_train_feats = np.vstack([smiles_to_fp(s) for s in X_train])\n",
        "X_val_feats   = np.vstack([smiles_to_fp(s) for s in X_val])\n",
        "X_test = dev_test['SMILES'].to_list()\n",
        "X_test_feats  = np.vstack([smiles_to_fp(s) for s in X_test])\n",
        "\n",
        "# Combine train and validation sets\n",
        "X_dev_feats = np.vstack([X_train_feats, X_val_feats])\n",
        "y_dev = np.vstack([y_train, y_val])\n",
        "\n",
        "# Test targets\n",
        "y_test = dev_test[['Tg', 'FFV', 'Tc', 'Density', 'Rg']].to_numpy()\n",
        "\n",
        "task_names = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
        "models = {}\n",
        "y_pred = np.zeros_like(y_test)\n",
        "\n",
        "# Train one random forest per task\n",
        "for idx, name in enumerate(task_names):\n",
        "    print('Training random forest for the task:', name)\n",
        "    y_col = y_dev[:, idx]\n",
        "    mask  = ~np.isnan(y_col)\n",
        "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf.fit(X_dev_feats[mask], y_col[mask])\n",
        "    models[name] = rf\n",
        "    # Predict on test set\n",
        "    y_pred[:, idx] = rf.predict(X_test_feats)\n",
        "\n",
        "# Compute MSE per task, skipping NaNs\n",
        "mse_per_task = {}\n",
        "for i, name in enumerate(task_names):\n",
        "    print('Predicting for the task:', name)\n",
        "    mask = ~np.isnan(y_test[:, i])\n",
        "    if mask.sum() > 0:\n",
        "        mse = mean_squared_error(y_test[mask, i], y_pred[mask, i])\n",
        "        mse_per_task[name] = mse\n",
        "    else:\n",
        "        mse_per_task[name] = np.nan\n",
        "\n",
        "print(\"MSE per task:\")\n",
        "for name, mse in mse_per_task.items():\n",
        "    print(f\"  {name}: {mse:.4f}\")\n",
        "\n",
        "# Compute overall MSE across all tasks, skipping NaNs\n",
        "mask_all = ~np.isnan(y_test)\n",
        "y_true_flat = y_test[mask_all]\n",
        "y_pred_flat = y_pred[mask_all]\n",
        "mse_overall = mean_squared_error(y_true_flat, y_pred_flat)\n",
        "print(f\"Overall MSE: {mse_overall:.4f}\")"
      ],
      "metadata": {
        "id": "wSVlaryaC03k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm as notebook_tqdm\n",
        "import tqdm\n",
        "tqdm.tqdm = notebook_tqdm\n",
        "tqdm.trange = notebook_tqdm\n",
        "\n",
        "from torch_molecule import GNNMolecularPredictor\n",
        "from torch_molecule.utils.search import ParameterType, ParameterSpec\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "search_parameters = {\n",
        "    'num_layer': ParameterSpec(\n",
        "        param_type=ParameterType.INTEGER,\n",
        "        value_range=(2, 5)\n",
        "    ),\n",
        "    'hidden_size': ParameterSpec(\n",
        "        param_type=ParameterType.INTEGER,\n",
        "        value_range=(64, 512)\n",
        "    ),\n",
        "    'learning_rate': ParameterSpec(\n",
        "        param_type=ParameterType.LOG_FLOAT,\n",
        "        value_range=(1e-4, 1e-2)\n",
        "    ),\n",
        "}\n",
        "\n",
        "gnn = GNNMolecularPredictor(\n",
        "    task_type=\"regression\",\n",
        "    num_task=5,\n",
        "    batch_size=192,\n",
        "    epochs=200,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Model initialized successfully\")\n",
        "X_train = dev_train['SMILES'].to_list()\n",
        "y_train = dev_train[['Tg', 'FFV', 'Tc', 'Density', 'Rg']].to_numpy()\n",
        "X_val = dev_val['SMILES'].to_list()\n",
        "y_val = dev_val[['Tg', 'FFV', 'Tc', 'Density', 'Rg']].to_numpy()\n",
        "gnn.autofit(\n",
        "    X_train = X_train,\n",
        "    y_train = y_train,\n",
        "    X_val = X_val,\n",
        "    y_val = y_val,\n",
        "    search_parameters=search_parameters,\n",
        "    n_trials = 10 # number of times searching the best hyper-parameters\n",
        ")"
      ],
      "metadata": {
        "id": "CTmDxCQVDgyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = dev_test['SMILES'].to_list()\n",
        "y_test = dev_test[['Tg', 'FFV', 'Tc', 'Density', 'Rg']].to_numpy()\n",
        "y_predict = gnn.predict(X_test)['prediction']\n",
        "\n",
        "task_names = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
        "\n",
        "# Compute MSE per task, skipping NaNs\n",
        "mse_per_task = {}\n",
        "for i, name in enumerate(task_names):\n",
        "    mask = ~np.isnan(y_test[:, i])\n",
        "    if mask.sum() > 0:\n",
        "        mse = mean_squared_error(y_test[mask, i], y_predict[mask, i])\n",
        "        mse_per_task[name] = mse\n",
        "    else:\n",
        "        mse_per_task[name] = np.nan  # no valid data\n",
        "\n",
        "print(\"MSE per task:\")\n",
        "for name, mse in mse_per_task.items():\n",
        "    print(f\"  {name}: {mse:.4f}\")\n",
        "\n",
        "# Compute overall MSE across all tasks, skipping NaNs\n",
        "mask_all = ~np.isnan(y_test)\n",
        "y_true_flat = y_test[mask_all]\n",
        "y_pred_flat = y_predict[mask_all]\n",
        "mse_overall = mean_squared_error(y_true_flat, y_pred_flat)\n",
        "\n",
        "print(f\"Overall MSE: {mse_overall:.4f}\")"
      ],
      "metadata": {
        "id": "BQeK84zEDhnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame(\n",
        "    test_preds,\n",
        "    columns=[\"Tg\",\"FFV\",\"Tc\",\"Density\",\"Rg\"]\n",
        ")\n",
        "submission_df.insert(0, \"id\", test_df[\"id\"])\n",
        "submission_df.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "oI8JgbqHEDDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qEGzNOU_Bd-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}